{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Neural-Network\n",
    "\n",
    "In this notebook we are going to apply machine learning (ML) to the MNIST hand-written digits dataset. Here we will be looking at different Neural Network architecture to perform digit recognition. To do this, you will need to install and import Keras and Tensorfow packages as seen below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import the required packages\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten, Activation, Bidirectional, RepeatVector, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...    28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...        0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import the MNIST dataset\n",
    "train = pd.read_csv(\"mnist_train.csv\")\n",
    "test = pd.read_csv(\"mnist_test.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of classes in the datset = 10\n",
    "set(train['label'])\n",
    "len(set(train['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#the labels\n",
    "set(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAEKCAYAAACWrQcQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x4eb39a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Show the first 9 images in the dataset\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    first_image = train.iloc[i,1:785]\n",
    "    first_image = np.array(first_image, dtype='float')\n",
    "    pixels = first_image.reshape((28, 28))\n",
    "    plt.imshow(pixels, cmap='gray',interpolation='none')\n",
    "    plt.title(\"Class {}\".format(train.iloc[i,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training neural networks (NN) it is important to make sure your training datset is evenly distributed and thus contained a balanced classes. Unbalanced class will result in a bias model as NN's tend to be lazy and will take majority rule. As we can see from the plot below the MNIST dataset contains balanced classes thus no additional data manipluation is needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x4fcfdda0>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEPCAYAAAC3NDh4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAo4FjlULpVkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5ac2ce10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the distribution of the training data\n",
    "sns.countplot(train['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format the data\n",
    "\n",
    "The dataset has already been broken into a training and test set (85/25). When using neural networks it is a good practice to linearly scale  the datat reducing the range of inputa variables from 0-255 to 0-1. Normalization is needed because it removes geometrical biases towards some of the dimensions of the data vectors. This is intended for faster approaching to global minima at error surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training matrix shape (60000, 784)\n",
      "Testing matrix shape (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "#define the test  and training data\n",
    "x_train = train.iloc[0:len(train),1:785]\n",
    "x_test = test.iloc[0:len(test),1:785]\n",
    "y_train =train.iloc[0:len(train),0]\n",
    "y_test = test.iloc[0:len(test),0]\n",
    "\n",
    "print(\"Training matrix shape\", x_train.shape)\n",
    "print(\"Testing matrix shape\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scale input data\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training target matrix shape (60000, 10)\n",
      "Testing target matrix shape (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.astype('int32')\n",
    "y_test = y_test.astype('int32')\n",
    "\n",
    "Y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "Y_test = keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "print(\"Training target matrix shape\", Y_train.shape)\n",
    "print(\"Testing target matrix shape\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Neural Network\n",
    "\n",
    "For the first iteration, lets build a basic Feed Forward Neural Network which has an input layer, one hiddne layer and an output layer. This this case we create a network with one hidden layers with 15 neurons as seen in the image below, and an output layer with 10 neurons.  \n",
    "\n",
    "This is a categorical (10 class) problem and this use need an output layer of 10 neurons with a 'softmax' activation function. For binary (2-class) problems, one node can be used in the output layer with a sigmoid function. \n",
    "\n",
    "Activation functions are an extremely important feature of the artificial neural networks. They basically decide whether a neuron should be activated or not. Whether the information that the neuron is receiving is relevant for the given information or should it be ignored. The non-linear activation fucntion used in the hidden and input layer is the 'ReLu' activation. More information about various activations can be found in the linkn below:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Activation_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](pic1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_38 (Dense)             (None, 15)                11775     \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 15)                240       \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 15)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 10)                160       \n",
      "=================================================================\n",
      "Total params: 12,175\n",
      "Trainable params: 12,175\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(15, input_shape=(784,),activation='relu'))    \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(15,  activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 5\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              #optimizer= Adam(lr=1e-03), \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.5712 - acc: 0.8214 - val_loss: 0.3118 - val_acc: 0.9151\n",
      "Epoch 2/5\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.5432 - acc: 0.8302 - val_loss: 0.2969 - val_acc: 0.9172\n",
      "Epoch 3/5\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.5344 - acc: 0.8339 - val_loss: 0.2961 - val_acc: 0.9194\n",
      "Epoch 4/5\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.5190 - acc: 0.8389 - val_loss: 0.2879 - val_acc: 0.9202\n",
      "Epoch 5/5\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.5052 - acc: 0.8425 - val_loss: 0.2842 - val_acc: 0.9219\n",
      "Validation accuracy: 0.9219166668256124, val_loss: 0.28423027777671817\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, Y_train,\n",
    "          validation_split=0.2,\n",
    "          #validation_data=(x_test,Y_test),\n",
    "          #verbose=1,\n",
    "          batch_size=batch_size, epochs=num_epochs)\n",
    "\n",
    "history = history.history\n",
    "val_acc = history['val_acc'][-1]\n",
    "val_loss = history['val_loss'][-1]\n",
    "print ('Validation accuracy: {acc}, val_loss: {loss}'.format(\n",
    "            acc=val_acc, loss=val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.27, Train accuracy: 92.57%\n"
     ]
    }
   ],
   "source": [
    "final_loss, final_acc = model.evaluate(x_train,Y_train, verbose=0)\n",
    "print(\"Train loss: {0:.2f}, Train accuracy: {1:.2f}%\".format(final_loss, final_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.29, Test accuracy: 92.26%\n"
     ]
    }
   ],
   "source": [
    "final_loss, final_acc = model.evaluate(x_test,Y_test,verbose=0)\n",
    "\n",
    "print(\"Test loss: {0:.2f}, Test accuracy: {1:.2f}%\".format(final_loss, final_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0     1    2    3    4    5    6    7    8    9\n",
      "0  960     0    0    1    0    5   10    3    1    0\n",
      "1    0  1114    3    4    1    3    3    0    7    0\n",
      "2   11     3  952   15    7    4   13    7   14    6\n",
      "3    2     1   18  917    0   35    0   15   16    6\n",
      "4    2     1    3    0  910    1   14    0    4   47\n",
      "5    8     2    0   38   13  774   13    7   35    2\n",
      "6   14     3    2    1    7   13  912    0    6    0\n",
      "7    0     7   18    8    2    1    1  947    1   43\n",
      "8    8    11    5   23   11   34   13   10  844   15\n",
      "9    7     4    0   11   41   12    3   27    8  896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "predictions = model.predict_classes(x_test)\n",
    "\n",
    "#fetch predictions\n",
    "preds=predictions.tolist()\n",
    "y_lbls = np.array(y_test.values)\n",
    "\n",
    "cm_1 = confusion_matrix(y_lbls, preds)\n",
    "print(pd.DataFrame(cm_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of correct classifcations:  9226\n"
     ]
    }
   ],
   "source": [
    "#Total number of number recignized in the test set\n",
    "b = np.asarray(cm_1)\n",
    "print('Total number of correct classifcations: ', np.trace(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve model architecture\n",
    "\n",
    "we can play around with the network architecture and try a variety of set ups to improve the models performance. \n",
    "- Increase training time (epochs)\n",
    "- Change batch size\n",
    "- Add more hidden layers\n",
    "- Use alternative activation functions\n",
    "- Use alternative optimizer algorithms\n",
    "- Add learning rates\n",
    "\n",
    "See model below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_41 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 200)               102600    \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 525,630\n",
      "Trainable params: 525,630\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(784,),activation='relu'))    \n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(200,  activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100,  activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 6s 120us/step - loss: 0.3498 - acc: 0.8931 - val_loss: 0.1371 - val_acc: 0.9573\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.1367 - acc: 0.9601 - val_loss: 0.0965 - val_acc: 0.9717\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.0979 - acc: 0.9705 - val_loss: 0.0861 - val_acc: 0.9743\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.0792 - acc: 0.9761 - val_loss: 0.0838 - val_acc: 0.9765\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 5s 99us/step - loss: 0.0633 - acc: 0.9810 - val_loss: 0.0766 - val_acc: 0.9797\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.0525 - acc: 0.9837 - val_loss: 0.0894 - val_acc: 0.9760\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 5s 102us/step - loss: 0.0480 - acc: 0.9850 - val_loss: 0.0991 - val_acc: 0.9728\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 5s 101us/step - loss: 0.0432 - acc: 0.9865 - val_loss: 0.0856 - val_acc: 0.9779\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.0405 - acc: 0.9874 - val_loss: 0.0771 - val_acc: 0.9798\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 5s 100us/step - loss: 0.0347 - acc: 0.9892 - val_loss: 0.0823 - val_acc: 0.9793\n",
      "Validation accuracy: 0.979333333492279, val_loss: 0.08232430503641566\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              #optimizer= Adam(lr=1e-03), \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, Y_train,\n",
    "          validation_split=0.2,\n",
    "          #validation_data=(x_test,Y_test),\n",
    "          #verbose=1,\n",
    "          batch_size=batch_size, epochs=num_epochs)\n",
    "\n",
    "history = history.history\n",
    "val_acc = history['val_acc'][-1]\n",
    "val_loss = history['val_loss'][-1]\n",
    "print ('Validation accuracy: {acc}, val_loss: {loss}'.format(\n",
    "            acc=val_acc, loss=val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.03, Train accuracy: 99.22%\n",
      "Test loss: 0.08, Test accuracy: 98.00%\n"
     ]
    }
   ],
   "source": [
    "final_loss1, final_acc1 = model.evaluate(x_train,Y_train, verbose=0)\n",
    "print(\"Train loss: {0:.2f}, Train accuracy: {1:.2f}%\".format(final_loss1, final_acc1*100))\n",
    "\n",
    "final_loss2, final_acc2 = model.evaluate(x_test,Y_test,verbose=0)\n",
    "\n",
    "print(\"Test loss: {0:.2f}, Test accuracy: {1:.2f}%\".format(final_loss2, final_acc2*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
